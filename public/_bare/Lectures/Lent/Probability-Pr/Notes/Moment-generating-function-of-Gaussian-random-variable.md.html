<p>
    For a Gaussian random variable <span class="inline-math">$X$</span> in <span class="inline-math">$\R^n$</span>, suppose it has mean <span class="inline-math">$\mu = \expect(X)$</span> and variance <span class="inline-math">$V = \op{var}(X) = \left(\op{cov}(X_i, X_j)\right)_{i,j=1}^n$</span>.
</p>
<p>
    For all <span class="inline-math">$u\in\R^n$</span>, the random variable <span class="inline-math">$u^T X \sim N(u^T \mu, u^T V u)$</span>. (<a href="/tripos-notes/Lectures/Lent/Probability-Pr/Notes/Derivation-mean-and-variance-of-projection-of-multivariate-random-variable.html">Derivation</a>)
    Note that <span class="inline-math">$u^T V u \geq 0$</span> so <span class="inline-math">$V$</span> is non-negative definite.
</p>
<p>
    Therefore the  generating function is
    <span class="display-math">$$ \begin{align*}
        M_X(\lambda) = \expect(e^{\lambda^T X}) = e^{\lambda^T \mu + \frac{1}{2}\lambda^T V\lambda}.
    \end{align*} $$</span>
    <a href="/tripos-notes/Lectures/Lent/Probability-Pr/Notes/Theorem-uniqueness-of-moment-generating-function.html">Hence</a> the distribution of <span class="inline-math">$X$</span> is uniquely determined by <span class="inline-math">$\mu$</span> and <span class="inline-math">$V$</span>.
    So we write <span class="inline-math">$X\sim N(\mu, V)$</span>.
</p>
